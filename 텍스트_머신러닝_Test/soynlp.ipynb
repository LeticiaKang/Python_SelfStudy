{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석/텍스트 클리닝\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "from konlpy.tag import Okt\n",
    "import re\n",
    "\n",
    "# 단어 추가를 위함\n",
    "# from ckonlpy.tag import Twitter\n",
    "\n",
    "# Soynlp 패키지 \n",
    "from soynlp.noun import LRNounExtractor\n",
    "from soynlp.word import WordExtractor\n",
    "from soynlp.tokenizer import LTokenizer\n",
    "from soynlp import DoublespaceLineCorpus\n",
    "# import urllib.request\n",
    "# from soynlp.word import WordExtractor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('기업데이터(30)_(전처리).csv').iloc[:, 1:]\n",
    "df.columns = [\"com\", \"date\", \"duty\", \"status\", \"star\", \"summary\", \"good\", \"bad\", \"expect\", \"doc\"]\n",
    "df.head()\n",
    "df1 = df[[\"com\", \"date\", \"duty\", \"doc\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불용어, 숫자, 띄어쓰기, 특수문자, 의성어, 이모티콘 Cleaning\n",
    "- doc -> processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15864\\3852439269.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[\"cleaning\"] = clean_text(df1[\"doc\"])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def clean_text(texts):\n",
    "    #이모티콘 제거\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                            \"]+\", flags=re.UNICODE)\n",
    "\n",
    "    #분석에 어긋나는 불용어구 제외 (특수문자, 의성어)\n",
    "    han = re.compile(r'[ㄱ-ㅎㅏ-ㅣ!?~,\".\\n\\r#\\ufeff\\u200d]')\n",
    "    \n",
    "    corpus = []\n",
    "    for i in range(0, len(texts)):\n",
    "        review = re.sub(r'[@%\\\\*=()/~#&\\+á?\\xc3\\xa1\\-\\|\\.\\:\\;\\!\\-\\,\\_\\~\\$\\'\\\"]', '',str(texts[i])) #remove punctuation\n",
    "        review = re.sub(r'\\d+','', str(texts[i]))# remove number\n",
    "        review = review.lower() #lower case\n",
    "        review = re.sub(r'\\s+', ' ', review) #remove extra space\n",
    "        # review = re.sub(r'<[^>]+>','',review) #remove Html tags\n",
    "        review = re.sub(r'\\s+', ' ', review) #remove spaces\n",
    "        review = re.sub(r\"^\\s+\", '', review) #remove space from start\n",
    "        review = re.sub(r'\\s+$', '', review) #remove space from the end\n",
    "        review = re.sub(han, '', review) #remove 특수문자, 의성어\n",
    "        review = re.sub(emoji_pattern, '', review) #remove 이모티콘\n",
    "        corpus.append(review)\n",
    "    return corpus\n",
    "\n",
    "df1[\"cleaning\"] = clean_text(df1[\"doc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### soynlp 사용\n",
    ": 기존의 형태소 분석기는 신조어나 형태소 분석기에 등록되지 않은 단어 같은 경우에는 제대로 구분하지 못하는 단점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install soynlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOYNLP의 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45400\n"
     ]
    }
   ],
   "source": [
    "# # 모델이 학습할 데이터 나누기/ 저장\n",
    "# doc = df1['cleaning'][:45400]\n",
    "# doc.to_csv('training_file.txt', index=False, header=None, sep=\"\\t\")\n",
    "\n",
    "# # 모델이 학습할 데이터 가져오기\n",
    "trainSet = DoublespaceLineCorpus(\"training_file.txt\") \n",
    "print(len(trainSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Noun Extractor] used default noun predictor; Sejong corpus predictor\n",
      "[Noun Extractor] used noun_predictor_sejong\n",
      "[Noun Extractor] All 2398 r features was loaded\n",
      "[Noun Extractor] scanning was done (L,R) has (69167, 38956) tokens\n",
      "[Noun Extractor] building L-R graph was done\n",
      "[Noun Extractor] 13358 nouns are extracted\n",
      "training was done. used memory 0.932 Gbory 0.498 Gb\n",
      "all cohesion probabilities was computed. # words = 15590\n",
      "all branching entropies was computed # words = 121494\n",
      "all accessor variety was computed # words = 121494\n"
     ]
    }
   ],
   "source": [
    "# 코드 분석 필요\n",
    "noun_extractor = LRNounExtractor()\n",
    "# ??\n",
    "nouns = noun_extractor.train_extract(list(trainSet)) # list of str like\n",
    "\n",
    "# ??\n",
    "word_extractor = WordExtractor(\n",
    "    min_frequency=50, # example\n",
    "    min_cohesion_forward=0.05,\n",
    "    min_right_branching_entropy=0.0\n",
    ")\n",
    "\n",
    "# ??\n",
    "word_extractor.train(list(trainSet))\n",
    "words = word_extractor.extract()\n",
    "\n",
    "cohesion_score = {word:score.cohesion_forward for word, score in words.items()}\n",
    "\n",
    "noun_scores = {noun:score.score for noun, score in nouns.items()}\n",
    "combined_scores = {noun:score + cohesion_score.get(noun, 0)\n",
    "    for noun, score in noun_scores.items()}\n",
    "combined_scores.update(\n",
    "    {subword:cohesion for subword, cohesion in cohesion_score.items()\n",
    "    if not (subword in combined_scores)}\n",
    ")\n",
    "\n",
    "tokenizer = LTokenizer(scores=combined_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "좋은 인력풀에서 일해볼 수 있는 기회여서 시야를 틀수도 있지만 부바부 전체적으로 자유로운 분위기 이지만 이또한 부바부로 생긴지 오래되지 않은 부서여서 매우 자유로운편이었음 실력일는 팀원이 아닌 리더에게 잘보이는 사람에게 과업을 몰아주는 정치질도 있음 물론 인센티브도 같이 뺏김 오래다니지 않아서 경영진까지 바라고 할게 없었다고 한다\n",
      "['좋은', '인력', '풀에서', '일해볼', '수', '있는', '기회', '여서', '시야', '를', '틀수도', '있지', '만', '부바', '부', '전체적', '으로', '자유', '로운', '분위기', '이지', '만', '이또', '한', '부바', '부로', '생긴지', '오래', '되지', '않은', '부서', '여서', '매우', '자유', '로운편이었음', '실력', '일는', '팀원', '이', '아닌', '리더', '에게', '잘보', '이는', '사람', '에게', '과업', '을', '몰아주', '는', '정치', '질도', '있음', '물론', '인센티브', '도', '같이', '뺏김', '오래', '다니지', '않아서', '경영진', '까지', '바라', '고', '할게', '없었다', '고', '한다']\n"
     ]
    }
   ],
   "source": [
    "# 잘 작동하는지 확인\n",
    "train_list=list(df1['cleaning'])\n",
    "print(str(train_list[34]))\n",
    "print(tokenizer.tokenize(str(train_list[34])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15864\\940875886.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['tokenize'] = \"\"\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15864\\940875886.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['tokenize'][num] = tokenizer.tokenize(str(train_list[num]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>com</th>\n",
       "      <th>date</th>\n",
       "      <th>duty</th>\n",
       "      <th>doc</th>\n",
       "      <th>cleaning</th>\n",
       "      <th>tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>네이버</td>\n",
       "      <td>2022. 11</td>\n",
       "      <td>디자인</td>\n",
       "      <td>커리어 경력 쌓고 싶은 사람에게 추천 수평적 사무실 분위기와 복지가 다른 곳 보다는...</td>\n",
       "      <td>커리어 경력 쌓고 싶은 사람에게 추천 수평적 사무실 분위기와 복지가 다른 곳 보다는...</td>\n",
       "      <td>[커리어, 경력, 쌓고, 싶은, 사람, 에게, 추천, 수평적, 사무실, 분위기, 와...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>네이버</td>\n",
       "      <td>2022. 11</td>\n",
       "      <td>전문직</td>\n",
       "      <td>자유로운 복장 분위기가 일단 편해서 좋았어요. 물론 업무는 당연히 강도가 있어야 할...</td>\n",
       "      <td>자유로운 복장 분위기가 일단 편해서 좋았어요 물론 업무는 당연히 강도가 있어야 할 ...</td>\n",
       "      <td>[자유, 로운, 복장, 분위기, 가, 일단, 편해서, 좋았어요, 물론, 업무, 는,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>네이버</td>\n",
       "      <td>2022. 11</td>\n",
       "      <td>IT/인터넷</td>\n",
       "      <td>워라밸과 성장을 동시에 챙길 수 있는 몇 안되는 기업 앞으로도 가장 전망이 좋은 플...</td>\n",
       "      <td>워라밸과 성장을 동시에 챙길 수 있는 몇 안되는 기업 앞으로도 가장 전망이 좋은 플...</td>\n",
       "      <td>[워라밸, 과, 성장, 을, 동시, 에, 챙길, 수, 있는, 몇, 안되는, 기업, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>네이버</td>\n",
       "      <td>2022. 11</td>\n",
       "      <td>IT/인터넷</td>\n",
       "      <td>개발자가 영향력을 좀 발휘하며 일할수 있는곳. it업계 1위 개발에만 집중하며 일할...</td>\n",
       "      <td>개발자가 영향력을 좀 발휘하며 일할수 있는곳 it업계 위 개발에만 집중하며 일할 수...</td>\n",
       "      <td>[개발자, 가, 영향력, 을, 좀, 발휘, 하며, 일할수, 있는곳, it, 업계, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>네이버</td>\n",
       "      <td>2022. 10</td>\n",
       "      <td>IT/인터넷</td>\n",
       "      <td>아르바이트 생이었지만 꿈의 직장이란게 이런 것이구나 느낄 수 있었다 휴가 연차 등 ...</td>\n",
       "      <td>아르바이트 생이었지만 꿈의 직장이란게 이런 것이구나 느낄 수 있었다 휴가 연차 등 ...</td>\n",
       "      <td>[아르바이트, 생이었지만, 꿈의, 직장, 이란게, 이런, 것이, 구나, 느낄, 수,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   com      date    duty                                                doc  \\\n",
       "0  네이버  2022. 11     디자인  커리어 경력 쌓고 싶은 사람에게 추천 수평적 사무실 분위기와 복지가 다른 곳 보다는...   \n",
       "1  네이버  2022. 11     전문직  자유로운 복장 분위기가 일단 편해서 좋았어요. 물론 업무는 당연히 강도가 있어야 할...   \n",
       "2  네이버  2022. 11  IT/인터넷  워라밸과 성장을 동시에 챙길 수 있는 몇 안되는 기업 앞으로도 가장 전망이 좋은 플...   \n",
       "3  네이버  2022. 11  IT/인터넷  개발자가 영향력을 좀 발휘하며 일할수 있는곳. it업계 1위 개발에만 집중하며 일할...   \n",
       "4  네이버  2022. 10  IT/인터넷  아르바이트 생이었지만 꿈의 직장이란게 이런 것이구나 느낄 수 있었다 휴가 연차 등 ...   \n",
       "\n",
       "                                            cleaning  \\\n",
       "0  커리어 경력 쌓고 싶은 사람에게 추천 수평적 사무실 분위기와 복지가 다른 곳 보다는...   \n",
       "1  자유로운 복장 분위기가 일단 편해서 좋았어요 물론 업무는 당연히 강도가 있어야 할 ...   \n",
       "2  워라밸과 성장을 동시에 챙길 수 있는 몇 안되는 기업 앞으로도 가장 전망이 좋은 플...   \n",
       "3  개발자가 영향력을 좀 발휘하며 일할수 있는곳 it업계 위 개발에만 집중하며 일할 수...   \n",
       "4  아르바이트 생이었지만 꿈의 직장이란게 이런 것이구나 느낄 수 있었다 휴가 연차 등 ...   \n",
       "\n",
       "                                            tokenize  \n",
       "0  [커리어, 경력, 쌓고, 싶은, 사람, 에게, 추천, 수평적, 사무실, 분위기, 와...  \n",
       "1  [자유, 로운, 복장, 분위기, 가, 일단, 편해서, 좋았어요, 물론, 업무, 는,...  \n",
       "2  [워라밸, 과, 성장, 을, 동시, 에, 챙길, 수, 있는, 몇, 안되는, 기업, ...  \n",
       "3  [개발자, 가, 영향력, 을, 좀, 발휘, 하며, 일할수, 있는곳, it, 업계, ...  \n",
       "4  [아르바이트, 생이었지만, 꿈의, 직장, 이란게, 이런, 것이, 구나, 느낄, 수,...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 빈 컬럼 만들기\n",
    "df1['tokenize'] = \"\"\n",
    "\n",
    "# 빈 컬럼에 토큰화된 결과 추가하기\n",
    "for num in range(len(df1)):\n",
    "    df1['tokenize'][num] = tokenizer.tokenize(str(train_list[num]))\n",
    "    \n",
    "# 결과 출력\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60573/60573 [00:00<00:00, 93888.34it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>com</th>\n",
       "      <th>date</th>\n",
       "      <th>duty</th>\n",
       "      <th>doc</th>\n",
       "      <th>cleaning</th>\n",
       "      <th>tokenize</th>\n",
       "      <th>cleaningTokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>네이버</td>\n",
       "      <td>2022. 11</td>\n",
       "      <td>디자인</td>\n",
       "      <td>커리어 경력 쌓고 싶은 사람에게 추천 수평적 사무실 분위기와 복지가 다른 곳 보다는...</td>\n",
       "      <td>커리어 경력 쌓고 싶은 사람에게 추천 수평적 사무실 분위기와 복지가 다른 곳 보다는...</td>\n",
       "      <td>[커리어, 경력, 쌓고, 싶은, 사람, 에게, 추천, 수평적, 사무실, 분위기, 와...</td>\n",
       "      <td>[커리어, 경력, 쌓고, 싶은, 사람, 추천, 수평적, 사무실, 분위기, 복지, 편...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>네이버</td>\n",
       "      <td>2022. 11</td>\n",
       "      <td>전문직</td>\n",
       "      <td>자유로운 복장 분위기가 일단 편해서 좋았어요. 물론 업무는 당연히 강도가 있어야 할...</td>\n",
       "      <td>자유로운 복장 분위기가 일단 편해서 좋았어요 물론 업무는 당연히 강도가 있어야 할 ...</td>\n",
       "      <td>[자유, 로운, 복장, 분위기, 가, 일단, 편해서, 좋았어요, 물론, 업무, 는,...</td>\n",
       "      <td>[자유, 로운, 복장, 분위기, 편해서, 좋았어요, 업무, 당연, 히, 강도, 있어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>네이버</td>\n",
       "      <td>2022. 11</td>\n",
       "      <td>IT/인터넷</td>\n",
       "      <td>워라밸과 성장을 동시에 챙길 수 있는 몇 안되는 기업 앞으로도 가장 전망이 좋은 플...</td>\n",
       "      <td>워라밸과 성장을 동시에 챙길 수 있는 몇 안되는 기업 앞으로도 가장 전망이 좋은 플...</td>\n",
       "      <td>[워라밸, 과, 성장, 을, 동시, 에, 챙길, 수, 있는, 몇, 안되는, 기업, ...</td>\n",
       "      <td>[워라밸, 성장, 동시, 챙길, 수, 안되는, 기업, 앞으로, 도, 가장, 전망, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>네이버</td>\n",
       "      <td>2022. 11</td>\n",
       "      <td>IT/인터넷</td>\n",
       "      <td>개발자가 영향력을 좀 발휘하며 일할수 있는곳. it업계 1위 개발에만 집중하며 일할...</td>\n",
       "      <td>개발자가 영향력을 좀 발휘하며 일할수 있는곳 it업계 위 개발에만 집중하며 일할 수...</td>\n",
       "      <td>[개발자, 가, 영향력, 을, 좀, 발휘, 하며, 일할수, 있는곳, it, 업계, ...</td>\n",
       "      <td>[개발자, 영향력, 발휘, 하며, 일할수, 있는곳, it, 업계, 위, 개발, 에만...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>네이버</td>\n",
       "      <td>2022. 10</td>\n",
       "      <td>IT/인터넷</td>\n",
       "      <td>아르바이트 생이었지만 꿈의 직장이란게 이런 것이구나 느낄 수 있었다 휴가 연차 등 ...</td>\n",
       "      <td>아르바이트 생이었지만 꿈의 직장이란게 이런 것이구나 느낄 수 있었다 휴가 연차 등 ...</td>\n",
       "      <td>[아르바이트, 생이었지만, 꿈의, 직장, 이란게, 이런, 것이, 구나, 느낄, 수,...</td>\n",
       "      <td>[아르바이트, 생이었지만, 꿈의, 직장, 이란게, 것이, 구나, 느낄, 수, 있었다...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   com      date    duty                                                doc  \\\n",
       "0  네이버  2022. 11     디자인  커리어 경력 쌓고 싶은 사람에게 추천 수평적 사무실 분위기와 복지가 다른 곳 보다는...   \n",
       "1  네이버  2022. 11     전문직  자유로운 복장 분위기가 일단 편해서 좋았어요. 물론 업무는 당연히 강도가 있어야 할...   \n",
       "2  네이버  2022. 11  IT/인터넷  워라밸과 성장을 동시에 챙길 수 있는 몇 안되는 기업 앞으로도 가장 전망이 좋은 플...   \n",
       "3  네이버  2022. 11  IT/인터넷  개발자가 영향력을 좀 발휘하며 일할수 있는곳. it업계 1위 개발에만 집중하며 일할...   \n",
       "4  네이버  2022. 10  IT/인터넷  아르바이트 생이었지만 꿈의 직장이란게 이런 것이구나 느낄 수 있었다 휴가 연차 등 ...   \n",
       "\n",
       "                                            cleaning  \\\n",
       "0  커리어 경력 쌓고 싶은 사람에게 추천 수평적 사무실 분위기와 복지가 다른 곳 보다는...   \n",
       "1  자유로운 복장 분위기가 일단 편해서 좋았어요 물론 업무는 당연히 강도가 있어야 할 ...   \n",
       "2  워라밸과 성장을 동시에 챙길 수 있는 몇 안되는 기업 앞으로도 가장 전망이 좋은 플...   \n",
       "3  개발자가 영향력을 좀 발휘하며 일할수 있는곳 it업계 위 개발에만 집중하며 일할 수...   \n",
       "4  아르바이트 생이었지만 꿈의 직장이란게 이런 것이구나 느낄 수 있었다 휴가 연차 등 ...   \n",
       "\n",
       "                                            tokenize  \\\n",
       "0  [커리어, 경력, 쌓고, 싶은, 사람, 에게, 추천, 수평적, 사무실, 분위기, 와...   \n",
       "1  [자유, 로운, 복장, 분위기, 가, 일단, 편해서, 좋았어요, 물론, 업무, 는,...   \n",
       "2  [워라밸, 과, 성장, 을, 동시, 에, 챙길, 수, 있는, 몇, 안되는, 기업, ...   \n",
       "3  [개발자, 가, 영향력, 을, 좀, 발휘, 하며, 일할수, 있는곳, it, 업계, ...   \n",
       "4  [아르바이트, 생이었지만, 꿈의, 직장, 이란게, 이런, 것이, 구나, 느낄, 수,...   \n",
       "\n",
       "                                    cleaningTokenize  \n",
       "0  [커리어, 경력, 쌓고, 싶은, 사람, 추천, 수평적, 사무실, 분위기, 복지, 편...  \n",
       "1  [자유, 로운, 복장, 분위기, 편해서, 좋았어요, 업무, 당연, 히, 강도, 있어...  \n",
       "2  [워라밸, 성장, 동시, 챙길, 수, 안되는, 기업, 앞으로, 도, 가장, 전망, ...  \n",
       "3  [개발자, 영향력, 발휘, 하며, 일할수, 있는곳, it, 업계, 위, 개발, 에만...  \n",
       "4  [아르바이트, 생이었지만, 꿈의, 직장, 이란게, 것이, 구나, 느낄, 수, 있었다...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불용어 사전 불러오기\n",
    "stopwords = list(pd.read_csv(\"stopwords_kej.csv\")['words'])\n",
    "# # 불용어 파일이 txt일 경우\n",
    "# stopwords = list(pd.read_csv(\"stopword_v2.txt\", sep = \"\\t\", encoding = \"utf-8\")['words'])\n",
    "stopwords.extend(\"이\")\n",
    "stopwords = set(stopwords)\n",
    "\n",
    "# 불용어 제거 함수\n",
    "def DeleteStopwords(cell):\n",
    "    words = [word for word in cell if word not in stopwords]\n",
    "    return words    \n",
    "\n",
    "# 형태소 분석 적용\n",
    "tokenizing_doc = []\n",
    "for cell in tqdm(df1['tokenize']):\n",
    "    tokenizing_doc.append(DeleteStopwords(cell))\n",
    "df1['cleaningTokenize'] = tokenizing_doc\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  words\n",
      "0    있는\n",
      "1    소생\n"
     ]
    }
   ],
   "source": [
    "# # ★★★★ stopwords 업데이트 꼭 하기~ ★★★★\n",
    "# save_stopwords = pd.DataFrame(stopwords, columns=[\"words\"])\n",
    "# print(save_stopwords.head(2))\n",
    "# save_stopwords.to_csv(\"stopwords_kej.csv\", encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 저장\n",
    "df1.to_csv('불용어처리 결과.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
